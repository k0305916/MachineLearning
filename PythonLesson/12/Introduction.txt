KeyWords:

深度学习可以被看作是一组算法的集合，这些算法能够高效地进行多层人工神经网络训练。
---反向传播算法
----反向传播误差，计算其对于网络中每个权重的导数，并更新模型。

时至今日，由于能够解决图像和语音识别等复杂问题，由深度学习算法所驱动的复杂神经网络被认为是最前沿的研究成果。
三层MLP的概念：一个输入层、一个隐层，以及一个输出层。隐层的所有单元完全连接到输入层上，同时输出层的单元也完全连接到了隐层中。如果网络中包含不止一个隐层，我们则称其为深度人工神经网络。


我们可以向MLP中加入任意数量的隐层来创建更深层的网络架构。实际上，可以将神经网络中的隐层数量及各单元看作是额外的超参，可
我们可以向MLP中加入任意数量的隐层来创建更深层的网络架构。实际上，可以将神经网络中的隐层数量及各单元看作是额外的超参，可以使用第6章中介绍过的交叉验证针对特定问题对它们进行优化。

不过，随着增加到网络中的隐层越来越多，通过反向传播算法计算得到的梯度误差也将变得越来越小。这个接近于不存在的梯度问题使得模型的学习非常具有挑战性。因此，特别发展出了针对此类深层神经网络架构的预处理算法，亦即所谓的深度学习。

通过独热（one-hot）向量表示方法，我们可以处理数据集中包含任意多个类别的分类任务。

我们将多层感知器的学习过程总结为三个简单步骤：
1）从输入层开始，通过网络向前传播（也就是正向传播）训练数据中的模式，以生成输出。
2）基于网络的输出，通过一个代价函数（稍后将有介绍）计算所需最小化的误差。
3）反向传播误差，计算其对于网络中每个权重的导数，并更新模型。

为了解决图像分类等复杂问题，我们需要在多层感知器模型中使用非线性激励函数，

多层感知器是一个典型的前馈人工神经网络。
此处的前馈是指每一层的输出都直接作为下一层的输入。


学习的文献：
·T.Hastie,J.Friedman,and R.Tibshirani.The Elements of Statistical Learning,Volume 2.Springer,2009.
·C.M.Bishop et al.Pattern Recognition and Machine Learning,Volume 1.Springer New York,2006.


数据集中的图像以字节形式存储，