keywords:
机器学习算法最终学习结果的优劣取决于两个主要因素：数据的质量和数据中蕴含的有用信息的数量。

将讨论主要的数据预处理技术，使用这些技术可以高效地构建好的机器学习模型。

处理缺失数据最简单的方法就是：将包含确实数据的特征（列）或者样本（行）从数据集中删除。
可通过dataframe.dropna方法来删除数据集中包含缺失值的行.
但也有一定的缺点，如：我们可能会删除过多的样本，导致分析结果可靠性不高。
从另一方面讲，如果删除了过多的特征列，有可能会面临丢失有价值信息的风险，
而这些信息是分类器用来区分类别所必需的。

均值均值：
我们可使用scikit-learn中的Impute类方便地实现此方法


决策树和随机森林是机器学习算法中为数不多的不需要进行特征缩放的算法。
然而，对大多数机器学习和优化算法而言，将特征的值缩放到相同的区间可以使其性能更佳，


而常用的降低泛化误差的方案有：
1）收集更多的训练数据
2）通过正则化引入罚项
3）选择一个参数相对较少的简单模型
4）降低数据的维度